import chess
import chess.engine
import pyautogui
import keyboard
import time
import cv2
import numpy as np
from PIL import ImageGrab
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import scipy


#engine = chess.engine.SimpleEngine.popen_uci("stockfish/stockfish-windows-x86-64-avx2.exe")

#def FindBestMove(fen):
#    fen = fen
#    board = chess.Board(fen)

#    # Use Stockfish to find the best move for the position
#    result = engine.play(board, chess.engine.Limit(time=2.0))
#    best_move = result.move

#    return best_move


#print("Put your mouse on the bottom left corner of the chess board and press \"space\"")
#keyboard.wait("space")
#bcx, bcy = pyautogui.position()
#print(bcx, bcy)
#time.sleep(1)

#print("Now put your mouse on the top right corner and press space.")
#keyboard.wait("space")
#tcx, tcy = pyautogui.position()
#print(tcx, tcy)

#area = (bcx, tcy, tcx, bcy)
#screenshot = ImageGrab.grab(bbox=area)
#screenshot_np = np.array(screenshot)
#gray = cv2.cvtColor(screenshot_np, cv2.COLOR_BGR2GRAY)

# Calculate the width and height of each grid cell
#height, width = gray.shape[:2]
#cell_width = width // 8
#cell_height = height // 8

# Split the screenshot into a grid of 8x8
#grid = []
#for y in range(8):
#    for x in range(8):
#        left = x * cell_width
#        top = y * cell_height
#        right = left + cell_width
#        bottom = top + cell_height
#        cell = gray[top:bottom, left:right]
#        grid.append(cell)





IMAGE_SIZE = (103, 102)

train_data_gen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
)

train_generator = train_data_gen.flow_from_directory(
    'ai-data',  # Replace with the path to your dataset directory
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical',
    subset='training',
)

validation_generator = train_data_gen.flow_from_directory(
    'practice-ai',  # Replace with the path to your dataset directory
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical',
    subset='validation',
)

# Load the pre-trained MobileNetV2 model
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet'
)

# Freeze the base model layers
base_model.trainable = False

# Add custom classification head
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(14, activation='softmax')  # Replace num_classes with the number of chess piece classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10,  # You can adjust the number of epochs
)

# Save the model for later use
model.save('chess_piece_recognition_model.h5')


#engine.quit()
