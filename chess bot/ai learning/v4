import chess
import chess.engine
import pyautogui
import keyboard
import time
import cv2
import numpy as np
from PIL import Image, ImageGrab
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import scipy
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

model = load_model("chess_piece_recognition_model.h5")


engine = chess.engine.SimpleEngine.popen_uci("stockfish/stockfish-windows-x86-64-avx2.exe")

def FindBestMove(fen):
    fen = fen
    board = chess.Board(fen)

    # Use Stockfish to find the best move for the position
    result = engine.play(board, chess.engine.Limit(time=2.0))
    best_move = result.move

    return best_move


print("Put your mouse on the bottom left corner of the chess board and press \"space\"")
keyboard.wait("space")
bcx, bcy = pyautogui.position()
print(bcx, bcy)
time.sleep(1)

print("Now put your mouse on the top right corner and press space.")
keyboard.wait("space")
tcx, tcy = pyautogui.position()
print(tcx, tcy)

area = (bcx, tcy, tcx, bcy)
screenshot = ImageGrab.grab(bbox=area)
screenshot_np = np.array(screenshot)
gray = cv2.cvtColor(screenshot_np, cv2.COLOR_BGR2GRAY)

# Calculate the width and height of each grid cell
height, width = gray.shape[:2]
cell_width = width // 8
cell_height = height // 8

if not os.path.exists("predicted_images"):
    os.makedirs("predicted_images")

# Split the screenshot into a grid of 8x8
# ... (previous code)

# Split the screenshot into a grid of 8x8
grid = []
for y in range(8):
    for x in range(8):
        left = x * cell_width
        top = y * cell_height
        right = left + cell_width
        bottom = top + cell_height
        cell = gray[top:bottom, left:right]

        # Resize cell to match the expected input shape (103x102)
        cell_resized = cv2.resize(cell, (103, 102), interpolation=cv2.INTER_LINEAR)

        # Convert grayscale cell to RGB and swap the dimensions
        cell_rgb = cv2.cvtColor(cell_resized, cv2.COLOR_GRAY2RGB)


        grid.append(cell_rgb)

grid_np = np.array(grid)

# Normalize the pixel values to the range [0, 1]
grid_normalized = grid_np / 255.0

# Add a batch dimension to the normalized grid
grid_normalized_batch = np.expand_dims(grid_normalized, axis=0)

# Make predictions using the pre-trained model
predictions = model.predict(grid_normalized_batch)


for i in range(64):
    cell_image = Image.fromarray(grid_np[i])
    cell_image.save(f"predicted_images/cell_{i}.png")

num_classes = predictions.shape[-1]


# Ensure the `chess_piece_mapping` dictionary matches the model's output classes
chess_piece_mapping = {
    0: "empty",
    1: "pawn",
    2: "rook",
    3: "knight",
    4: "bishop",
    5: "queen",
    6: "king"
    # Add more mappings if needed to cover all classes up to `num_classes - 1`
    # 7: "another_class",
    # ...
}

# Iterate through each grid cell and print the predicted chess piece
for y in range(8):
    for x in range(8):
        cell_index = y * 8 + x
        predicted_class = np.argmax(predictions[cell_index])
        if predicted_class in chess_piece_mapping:
            predicted_piece = chess_piece_mapping[predicted_class]
        else:
            predicted_piece = "unknown"  # Handle cases where the class is not in the mapping
        print(f"Grid cell ({x}, {y}): {predicted_piece}")





"""IMAGE_SIZE = (64, 102, 3)

def resize_input(image):
    return tf.image.resize(image, (IMAGE_SIZE[0], IMAGE_SIZE[1]))

train_data_gen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
)

# Replace 'ai-data' and 'practice-ai' with the paths to your training and validation datasets
train_generator = train_data_gen.flow_from_directory(
    'ai-data',
    target_size=IMAGE_SIZE[:2],  # Adjust to (64, 102) for the new shape
    batch_size=32,
    class_mode='categorical',
    subset='training',
)

validation_generator = train_data_gen.flow_from_directory(
    'practice-ai',
    target_size=IMAGE_SIZE[:2],  # Adjust to (64, 102) for the new shape
    batch_size=32,
    class_mode='categorical',
    subset='validation',
)

# Load the pre-trained MobileNetV2 model
base_model = MobileNetV2(
    input_shape=None,
    include_top=False,
    weights='imagenet'
)

# Resize the input images to the desired shape using a Lambda layer
input_layer = tf.keras.layers.Input(shape=IMAGE_SIZE)
resized_input = Lambda(resize_input)(input_layer)
base_model = Model(inputs=input_layer, outputs=base_model(resized_input))

# Freeze the base model layers
base_model.trainable = False

# Add custom classification head
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(14, activation='softmax')  # Replace 14 with the number of chess piece classes
])

# Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10,  # You can adjust the number of epochs
)

# Save the model for later use
model.save('chess_piece_recognition_model.h5')"""


#engine.quit()
