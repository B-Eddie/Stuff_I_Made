import chess
import chess.engine
import pyautogui
import keyboard
import time
import cv2
import numpy as np
from PIL import Image, ImageGrab
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import scipy
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator



"""model = load_model("chess_piece_recognition_model.h5")


engine = chess.engine.SimpleEngine.popen_uci("stockfish/stockfish-windows-x86-64-avx2.exe")

def FindBestMove(fen):
    fen = fen
    board = chess.Board(fen)

    # Use Stockfish to find the best move for the position
    result = engine.play(board, chess.engine.Limit(time=2.0))
    best_move = result.move

    return best_move


print("Put your mouse on the bottom left corner of the chess board and press \"space\"")
keyboard.wait("space")
bcx, bcy = pyautogui.position()
print(bcx, bcy)
time.sleep(1)

print("Now put your mouse on the top right corner and press space.")
keyboard.wait("space")
tcx, tcy = pyautogui.position()
print(tcx, tcy)

area = (bcx, tcy, tcx, bcy)
screenshot = ImageGrab.grab(bbox=area)
screenshot_np = np.array(screenshot)
gray = cv2.cvtColor(screenshot_np, cv2.COLOR_BGR2GRAY)

# Calculate the width and height of each grid cell
height, width = gray.shape[:2]
cell_width = width // 8
cell_height = height // 8

if not os.path.exists("predicted_images"):
    os.makedirs("predicted_images")


# Split the screenshot into a grid of 8x8
grid = []
for y in range(8):
    for x in range(8):
        left = x * cell_width
        top = y * cell_height
        right = left + cell_width
        bottom = top + cell_height
        cell = gray[top:bottom, left:right]

        # Resize cell to match the expected input shape (103x102)
        cell_resized = cv2.resize(cell, (103, 102), interpolation=cv2.INTER_LINEAR)

        # Convert grayscale cell to RGB and swap the dimensions
        cell_rgb = cv2.cvtColor(cell_resized, cv2.COLOR_GRAY2RGB)


        grid.append(cell_rgb)

grid_np = np.array(grid)

# Normalize the pixel values to the range [0, 1]
grid_normalized = grid_np / 255.0

# Add a batch dimension to the normalized grid
grid_normalized_batch = np.expand_dims(grid_normalized, axis=0)

# Make predictions using the pre-trained model
predictions = model.predict(grid_normalized_batch)


for i in range(64):
    cell_image = Image.fromarray(grid_np[i])
    cell_image.save(f"predicted_images/cell_{i}.png")

num_classes = predictions.shape[-1]


# Ensure the `chess_piece_mapping` dictionary matches the model's output classes
chess_piece_mapping = {
    0: "empty",
    1: "pawn",
    2: "rook",
    3: "knight",
    4: "bishop",
    5: "queen",
    6: "king"
    # Add more mappings if needed to cover all classes up to `num_classes - 1`
    # 7: "another_class",
    # ...
}

# Iterate through each grid cell and print the predicted chess piece
for y in range(8):
    for x in range(8):
        cell_index = y * 8 + x
        predicted_class = np.argmax(predictions[cell_index])
        if predicted_class in chess_piece_mapping:
            predicted_piece = chess_piece_mapping[predicted_class]
        else:
            predicted_piece = "unknown"  # Handle cases where the class is not in the mapping
        print(f"Grid cell ({x}, {y}): {predicted_piece}")"""





IMAGE_SIZE = (103, 102)

train_data_gen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
)

train_generator = train_data_gen.flow_from_directory(
    'ai-data',  # Replace with the path to your dataset directory
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical',
    subset='training',
)

validation_generator = train_data_gen.flow_from_directory(
    'practice-ai',  # Replace with the path to your dataset directory
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical',
    subset='validation',
)


# Load the pre-trained MobileNetV2 model
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet'
)


# Freeze the base model layers
base_model.trainable = False

# Add custom classification head
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(14, activation='softmax')  # Replace num_classes with the number of chess piece classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10,  # 10
)


# Save the model for later use
model.save('chess_piece_recognition_model.h5')




"""model = load_model("chess_piece_recognition_model.h5")

# Load the test image
test_images_folder = "test_images_for_end"
image_files = [os.path.join(test_images_folder, file) for file in os.listdir(test_images_folder) if file.endswith(".png")]

# Assuming your model has 7 classes (empty, pawn, rook, knight, bishop, queen, king)
chess_piece_mapping = {
    0: "empty",
    1: "pawn",
    2: "rook",
    3: "knight",
    4: "bishop",
    5: "queen",
    6: "king"
}

for image_path in image_files:
    img = tf.keras.utils.load_img(image_path, target_size=(103, 102))
    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)  # Create a batch dimension

    # Preprocess the image (optional, depends on how the model was trained)
    img_array /= 255.0

    # Make prediction using the model
    predictions = model.predict(img_array)

    # Get the predicted class index and corresponding piece name
    predicted_class = np.argmax(predictions[0])
    if predicted_class in chess_piece_mapping:
        predicted_piece = chess_piece_mapping[predicted_class]
    else:
        predicted_piece = "unknown"

    # Get the confidence score of the prediction
    confidence_score = 100 * np.max(tf.nn.softmax(predictions[0]))

    print(f"Image: {os.path.basename(image_path)} - Predicted piece: {predicted_piece} - Confidence: {confidence_score:.2f}%")"""
#engine.quit()
