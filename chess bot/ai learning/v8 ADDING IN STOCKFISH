import chess
import chess.engine
import pyautogui
import keyboard
import time
import cv2
import numpy as np
from PIL import Image, ImageGrab
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import scipy
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

model = load_model("chess_piece_recognition_model.h5")

engine = chess.engine.SimpleEngine.popen_uci("stockfish/stockfish-windows-x86-64-avx2.exe")


def FindBestMove(fen):
    fen = fen
    board = chess.Board(fen)

    # Use Stockfish to find the best move for the position
    result = engine.play(board, chess.engine.Limit(time=2.0))
    best_move = result.move

    return best_move


print("Put your mouse on the bottom left corner of the chess board and press \"space\"")
keyboard.wait("space")
bcx, bcy = pyautogui.position()
print(bcx, bcy)
time.sleep(1)

print("Now put your mouse on the top right corner and press space.")
keyboard.wait("space")
tcx, tcy = pyautogui.position()
print(tcx, tcy)

area = (bcx, tcy, tcx, bcy)

which_color_iam = input("Which color are you/I playing as?: ")

"""
IMAGE_SIZE = (103, 102)

data_augmentation = Sequential([
    #tf.keras.layers.RandomFlip("horizontal", input_shape=(*IMAGE_SIZE, 3)),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])


train_data_gen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
)

train_generator = train_data_gen.flow_from_directory(
    'ai-data',  # Replace with the path to your dataset directory
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical',
    subset='training',
)

validation_generator = train_data_gen.flow_from_directory(
    'practice-ai',  # Replace with the path to your dataset directory
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical',
    subset='validation',
)


# Load the pre-trained MobileNetV2 model
base_model = MobileNetV2( #MobileNetV2  or tf.keras.applications.ResNet50
    input_shape=(*IMAGE_SIZE, 3),
    include_top=False,
    weights='imagenet'
)


# Freeze the base model layers
base_model.trainable = False

# Add custom classification head
model = Sequential([
    data_augmentation,
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(28, activation='softmax')  # Replace 14 with the number of chess piece classes
])

# Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10,  # 10
)


# Save the model for later use
model.save('chess_piece_recognition_model.h5')"""

# Load the test image
test_images_folder = "screenshots_for_board/"
image_files = [os.path.join(test_images_folder, file) for file in os.listdir(test_images_folder) if
               file.endswith(".png")]

# Assuming your model has 7 classes (empty, pawn, rook, knight, bishop, queen, king)
chess_piece_mapping = {
    0: '1black_bishop',
    1: '1black_king',
    2: '1black_knight',
    3: '1black_pawn',
    4: '1black_queen',
    5: '1black_rook',
    6: '1black_space',
    7: '1white_bishop',
    8: '1white_king',
    9: '1white_knight',
    10: '1white_pawn',
    11: '1white_queen',
    12: '1white_rook',
    13: '1white_space',
    14: 'black_bishop',
    15: 'black_king',
    16: 'black_knight',
    17: 'black_pawn',
    18: 'black_queen',
    19: 'black_rook',
    20: 'black_space',
    21: 'white_bishop',
    22: 'white_king',
    23: 'white_knight',
    24: 'white_pawn',
    25: 'white_queen',
    26: 'white_rook',
    27: 'white_space',
}

file_path = "screenshots_for_board/"
files = os.listdir(file_path)


def screenshot():
    screenshot = ImageGrab.grab(bbox=area)
    screenshot_np = np.array(screenshot)
    gray = cv2.cvtColor(screenshot_np, cv2.COLOR_BGR2GRAY)

    # Calculate the width and height of each grid cell
    height, width = gray.shape[:2]
    cell_width = width // 8
    cell_height = height // 8

    for file in files:
        file_path_to_delete = os.path.join(file_path, file)
        os.remove(file_path_to_delete)

    for y in range(8):
        for x in range(8):
            left = x * cell_width
            top = y * cell_height
            right = left + cell_width
            bottom = top + cell_height
            cell = screenshot.crop((left, top, right, bottom))
            name = f"{x}_{y}.png"
            cell.save(os.path.join(file_path, name))


screenshot()

all_the_pieces = []


def predictImages(*list):
    for image_path in list:
        img = tf.keras.utils.load_img(image_path, target_size=(103, 102))
        img_array = tf.keras.utils.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)  # Create a batch dimension

        # Preprocess the image (optional, depends on how the model was trained)
        img_array /= 255.0

        # Make prediction using the model
        predictions = model.predict(img_array)

        # Get the predicted class index and corresponding piece name
        predicted_class = np.argmax(predictions[0])
        if predicted_class in chess_piece_mapping:
            predicted_piece = chess_piece_mapping[predicted_class]
        else:
            predicted_piece = "unknown"

        confidence_score = 100 * np.max(tf.nn.softmax(predictions[0]))

        print(f"Image: {os.path.basename(image_path)} - Predicted piece: {predicted_piece} - Confidence: {confidence_score:.2f}%")
        all_the_pieces.append(predicted_piece)


predictImages(*image_files)

piece_letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
coordinates_of_pieces = {}  # {1, 2: }
refined_coordinates_of_pieces = {}

for i, piece in enumerate(all_the_pieces):
    #row = piece_letters[i // 8]
    row = i // 8
    col = 7 - (i % 8)
    coordinate = f"{row}, {col}"
    coordinates_of_pieces[coordinate] = piece
print(coordinates_of_pieces)

for coordinate in coordinates_of_pieces:
    if coordinates_of_pieces[coordinate] == "black_bishop" or coordinates_of_pieces[coordinate] == "1black_bishop":
        refined_coordinates_of_pieces[coordinate] = "b"
    elif coordinates_of_pieces[coordinate] == "black_king" or coordinates_of_pieces[coordinate] == "1black_king":
        refined_coordinates_of_pieces[coordinate] = "k"
    elif coordinates_of_pieces[coordinate] == "black_knight" or coordinates_of_pieces[coordinate] == "1black_knight":
        refined_coordinates_of_pieces[coordinate] = "n"
    elif coordinates_of_pieces[coordinate] == "black_pawn" or coordinates_of_pieces[coordinate] == "1black_pawn":
        refined_coordinates_of_pieces[coordinate] = "p"
    elif coordinates_of_pieces[coordinate] == "black_queen" or coordinates_of_pieces[coordinate] == "1black_queen":
        refined_coordinates_of_pieces[coordinate] = "q"
    elif coordinates_of_pieces[coordinate] == "black_rook" or coordinates_of_pieces[coordinate] == "1black_rook":
        refined_coordinates_of_pieces[coordinate] = "r"
    elif coordinates_of_pieces[coordinate] == "white_bishop" or coordinates_of_pieces[coordinate] == "1white_bishop":
        refined_coordinates_of_pieces[coordinate] = "B"
    elif coordinates_of_pieces[coordinate] == "white_king" or coordinates_of_pieces[coordinate] == "1white_king":
        refined_coordinates_of_pieces[coordinate] = "K"
    elif coordinates_of_pieces[coordinate] == "white_knight" or coordinates_of_pieces[coordinate] == "1white_knight":
        refined_coordinates_of_pieces[coordinate] = "N"
    elif coordinates_of_pieces[coordinate] == "white_pawn" or coordinates_of_pieces[coordinate] == "1white_pawn":
        refined_coordinates_of_pieces[coordinate] = "P"
    elif coordinates_of_pieces[coordinate] == "white_queen" or coordinates_of_pieces[coordinate] == "1white_queen":
        refined_coordinates_of_pieces[coordinate] = "Q"
    elif coordinates_of_pieces[coordinate] == "white_rook" or coordinates_of_pieces[coordinate] == "1white_rook":
        refined_coordinates_of_pieces[coordinate] = "R"
    else:
        pass

#Game Loop

def pieces_to_fen(board_dict, active_color="w"):
    # Initialize an empty FEN string
    fen = ""

    # Convert the board_dict into a 2D list to represent the chess board
    board = [["." for _ in range(8)] for _ in range(8)]
    for coord, piece in board_dict.items():
        x, y = map(int, coord.split(", "))  # Convert the x, y coordinates
        # Convert the x, y coordinates to board indices
        rowe = 7 - y
        cole = x
        board[rowe][cole] = piece


    # Convert the board representation to FEN format
    for rowe in board:
        empty_squares = 0
        for square in rowe:
            if square == ".":
                empty_squares += 1
            else:
                if empty_squares > 0:
                    fen += str(empty_squares)
                    empty_squares = 0
                fen += square
        if empty_squares > 0:
            fen += str(empty_squares)
        fen += "/"

    # Remove the trailing slash and add the other FEN components
    fen = fen[:-1]  # Remove the trailing slash
    fen += f" {active_color} - - 0 1"  # Specify the active color and assume no castling rights or en passant square

    return fen




FEN = pieces_to_fen(refined_coordinates_of_pieces, which_color_iam)

print(FindBestMove(FEN))


engine.quit()
exit()
